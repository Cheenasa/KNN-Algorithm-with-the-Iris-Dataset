# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5EjWzPa1Fw1RhGsuv5qHZ1UjVCa0uH1
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

# Load the IRIS dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Rescale the dataset
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# List of k values to try
k_values = [1, 3, 5, 7, 9]

# Plot decision boundaries for different k values
fig, axs = plt.subplots(nrows=len(k_values), ncols=3, figsize=(15, 5 * len(k_values)))

for j, k in enumerate(k_values):
    for i in range(3):
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(X_train_scaled[:, [i, (i+1) % 3]], y_train)

        # Create a meshgrid
        x_min, x_max = X_train_scaled[:, i].min() - 1, X_train_scaled[:, i].max() + 1
        y_min, y_max = X_train_scaled[:, (i+1) % 3].min() - 1, X_train_scaled[:, (i+1) % 3].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                             np.arange(y_min, y_max, 0.02))



        Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)

        # Plot decision boundary and data points
        axs[j][i].contourf(xx, yy, Z, alpha=0.4)

        for c in range(3):
            axs[j][i].scatter(X_train_scaled[y_train == c, i], X_train_scaled[y_train == c, (i+1) % 3], edgecolors='k', label=f'Class {c}')

        axs[j][i].set_title(f'k = {k}, Feature {i+1} vs Feature {(i+1) % 3 + 1}')
        axs[j][i].legend()

plt.tight_layout()
plt.show()