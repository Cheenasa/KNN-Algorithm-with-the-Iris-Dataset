# -*- coding: utf-8 -*-
"""Homework_Machine_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VPzIdDq6O56FzBMPw-34aLYw1f5T1Wg1
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report

# Load Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],
                     columns= iris['feature_names'] + ['target'])
print(f'The dataset has {iris_df.shape[0]} rows and {iris_df.shape[1]} columns.')
iris_df.head(5)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize a scaler and scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define a list of K values to try
k_values = list(range(1, 11))

# Dictionary to store cross-validation scores for each K value
cv_scores = {}

# Perform cross-validation for each K value
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')
    cv_scores[k] = np.mean(scores)

# Print the cross-validation scores for each K value
for k, score in cv_scores.items():
    print(f"K = {k}: Mean Accuracy = {score}")

# Select the best value of K
best_k = max(cv_scores, key=cv_scores.get)
print(f"The best value of K is: {best_k}")

# Train the final KNN model with the best value of K
final_knn = KNeighborsClassifier(n_neighbors=best_k)
final_knn.fit(X_train_scaled, y_train)

# Function to plot decision boundaries with legend
def plot_decision_boundary(X, y, model):
    h = .02  # step size in the mesh
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    # Predict the labels for all points in the mesh
    Z = model.predict(np.c_[xx.ravel(), yy.ravel(), np.zeros_like(xx.ravel()), np.zeros_like(xx.ravel())])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.3)

    # Plot training points for each class with different markers
    for i, class_label in enumerate(np.unique(y)):
        plt.scatter(X[y == class_label, 0], X[y == class_label, 1], c=[plt.cm.tab10(i)], edgecolors='none' , s=20, label=f'Class {class_label}')

    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('Decision Boundaries')
    plt.legend()

# Visualize decision boundaries for the first two features
plt.figure(figsize=(10, 6))
plot_decision_boundary(X_train_scaled[:, :2], y_train, final_knn)
plt.show()

# Make predictions on the test set
y_pred = final_knn.predict(X_test_scaled)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# Visualize decision boundaries for the first two features
plt.figure(figsize=(10, 6))
plot_decision_boundary(X_test_scaled[:, :2], y_test, final_knn)
plt.show()

print(classification_report(y_test, y_pred))